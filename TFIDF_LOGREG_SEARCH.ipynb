{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "\n",
    "from gc import collect\n",
    "from utils_toxic import feat_engine, clean\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TARGET = ['identity_hate', 'insult', 'obscene','severe_toxic', 'threat', 'toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text  toxic  \\\n",
       "id                                                                           \n",
       "0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "id                                                                      \n",
       "0000997932d777bf             0        0       0       0              0  \n",
       "000103f0d9cfb60f             0        0       0       0              0  \n",
       "000113f07ec002fd             0        0       0       0              0  \n",
       "0001b41b1c6bb37e             0        0       0       0              0  \n",
       "0001d958c54c6e35             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  pd.read_csv('data/train.csv', sep=',', index_col='id')\n",
    "#data['train'] = 1\n",
    "#data = pd.concat([data, pd.read_csv('data/test.csv', sep=',', index_col='id')], axis=0)\n",
    "#data.train.fillna(0, inplace=True)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>count_sent</th>\n",
       "      <th>count_word</th>\n",
       "      <th>count_unique_word</th>\n",
       "      <th>...</th>\n",
       "      <th>word_unique_percent</th>\n",
       "      <th>punct_percent</th>\n",
       "      <th>ip</th>\n",
       "      <th>count_ip</th>\n",
       "      <th>link</th>\n",
       "      <th>count_links</th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_id_flag</th>\n",
       "      <th>username</th>\n",
       "      <th>count_usernames</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>95.348837</td>\n",
       "      <td>23.255814</td>\n",
       "      <td>[89.205.38.27]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>70.588235</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>92.857143</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>113</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>72.566372</td>\n",
       "      <td>18.584071</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text  toxic  \\\n",
       "id                                                                           \n",
       "0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "id                                                                       \n",
       "0000997932d777bf             0        0       0       0              0   \n",
       "000103f0d9cfb60f             0        0       0       0              0   \n",
       "000113f07ec002fd             0        0       0       0              0   \n",
       "0001b41b1c6bb37e             0        0       0       0              0   \n",
       "0001d958c54c6e35             0        0       0       0              0   \n",
       "\n",
       "                  count_sent  count_word  count_unique_word       ...         \\\n",
       "id                                                                ...          \n",
       "0000997932d777bf           2          43                 41       ...          \n",
       "000103f0d9cfb60f           1          17                 17       ...          \n",
       "000113f07ec002fd           1          42                 39       ...          \n",
       "0001b41b1c6bb37e           5         113                 82       ...          \n",
       "0001d958c54c6e35           1          13                 13       ...          \n",
       "\n",
       "                  word_unique_percent  punct_percent              ip  \\\n",
       "id                                                                     \n",
       "0000997932d777bf            95.348837      23.255814  [89.205.38.27]   \n",
       "000103f0d9cfb60f           100.000000      70.588235              []   \n",
       "000113f07ec002fd            92.857143      14.285714              []   \n",
       "0001b41b1c6bb37e            72.566372      18.584071              []   \n",
       "0001d958c54c6e35           100.000000      38.461538              []   \n",
       "\n",
       "                  count_ip  link  count_links  article_id  article_id_flag  \\\n",
       "id                                                                           \n",
       "0000997932d777bf         1    []            0          []                0   \n",
       "000103f0d9cfb60f         0    []            0          []                0   \n",
       "000113f07ec002fd         0    []            0          []                0   \n",
       "0001b41b1c6bb37e         0    []            0          []                0   \n",
       "0001d958c54c6e35         0    []            0          []                0   \n",
       "\n",
       "                 username  count_usernames  \n",
       "id                                          \n",
       "0000997932d777bf       []                0  \n",
       "000103f0d9cfb60f       []                0  \n",
       "000113f07ec002fd       []                0  \n",
       "0001b41b1c6bb37e       []                0  \n",
       "0001d958c54c6e35       []                0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = feat_engine(data)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.comment_text = data.comment_text.apply(lambda x :clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comment_text</th>\n",
       "      <td>explanationwhy edit make username hardcore met...</td>\n",
       "      <td>d'aww ! match background colour I am seemingly...</td>\n",
       "      <td>hey man , I am really try edit war . it is guy...</td>\n",
       "      <td>\" morei cannot make real suggestions improveme...</td>\n",
       "      <td>, sir , hero . chance remember page that is ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_toxic</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obscene</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity_hate</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_sent</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_word</th>\n",
       "      <td>43</td>\n",
       "      <td>17</td>\n",
       "      <td>42</td>\n",
       "      <td>113</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_unique_word</th>\n",
       "      <td>41</td>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "      <td>82</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_letters</th>\n",
       "      <td>264</td>\n",
       "      <td>112</td>\n",
       "      <td>233</td>\n",
       "      <td>622</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_punctuations</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_words_upper</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_words_title</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_stopwords</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_word_len</th>\n",
       "      <td>5.16279</td>\n",
       "      <td>5.58824</td>\n",
       "      <td>4.57143</td>\n",
       "      <td>4.48673</td>\n",
       "      <td>4.23077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_unique_percent</th>\n",
       "      <td>95.3488</td>\n",
       "      <td>100</td>\n",
       "      <td>92.8571</td>\n",
       "      <td>72.5664</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>punct_percent</th>\n",
       "      <td>23.2558</td>\n",
       "      <td>70.5882</td>\n",
       "      <td>14.2857</td>\n",
       "      <td>18.5841</td>\n",
       "      <td>38.4615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip</th>\n",
       "      <td>[89.205.38.27]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_ip</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_links</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id_flag</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_usernames</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "id                                                    0000997932d777bf  \\\n",
       "comment_text         explanationwhy edit make username hardcore met...   \n",
       "toxic                                                                0   \n",
       "severe_toxic                                                         0   \n",
       "obscene                                                              0   \n",
       "threat                                                               0   \n",
       "insult                                                               0   \n",
       "identity_hate                                                        0   \n",
       "count_sent                                                           2   \n",
       "count_word                                                          43   \n",
       "count_unique_word                                                   41   \n",
       "count_letters                                                      264   \n",
       "count_punctuations                                                  10   \n",
       "count_words_upper                                                    2   \n",
       "count_words_title                                                   11   \n",
       "count_stopwords                                                     18   \n",
       "mean_word_len                                                  5.16279   \n",
       "word_unique_percent                                            95.3488   \n",
       "punct_percent                                                  23.2558   \n",
       "ip                                                      [89.205.38.27]   \n",
       "count_ip                                                             1   \n",
       "link                                                                []   \n",
       "count_links                                                          0   \n",
       "article_id                                                          []   \n",
       "article_id_flag                                                      0   \n",
       "username                                                            []   \n",
       "count_usernames                                                      0   \n",
       "\n",
       "id                                                    000103f0d9cfb60f  \\\n",
       "comment_text         d'aww ! match background colour I am seemingly...   \n",
       "toxic                                                                0   \n",
       "severe_toxic                                                         0   \n",
       "obscene                                                              0   \n",
       "threat                                                               0   \n",
       "insult                                                               0   \n",
       "identity_hate                                                        0   \n",
       "count_sent                                                           1   \n",
       "count_word                                                          17   \n",
       "count_unique_word                                                   17   \n",
       "count_letters                                                      112   \n",
       "count_punctuations                                                  12   \n",
       "count_words_upper                                                    1   \n",
       "count_words_title                                                    3   \n",
       "count_stopwords                                                      2   \n",
       "mean_word_len                                                  5.58824   \n",
       "word_unique_percent                                                100   \n",
       "punct_percent                                                  70.5882   \n",
       "ip                                                                  []   \n",
       "count_ip                                                             0   \n",
       "link                                                                []   \n",
       "count_links                                                          0   \n",
       "article_id                                                          []   \n",
       "article_id_flag                                                      0   \n",
       "username                                                            []   \n",
       "count_usernames                                                      0   \n",
       "\n",
       "id                                                    000113f07ec002fd  \\\n",
       "comment_text         hey man , I am really try edit war . it is guy...   \n",
       "toxic                                                                0   \n",
       "severe_toxic                                                         0   \n",
       "obscene                                                              0   \n",
       "threat                                                               0   \n",
       "insult                                                               0   \n",
       "identity_hate                                                        0   \n",
       "count_sent                                                           1   \n",
       "count_word                                                          42   \n",
       "count_unique_word                                                   39   \n",
       "count_letters                                                      233   \n",
       "count_punctuations                                                   6   \n",
       "count_words_upper                                                    0   \n",
       "count_words_title                                                    2   \n",
       "count_stopwords                                                     20   \n",
       "mean_word_len                                                  4.57143   \n",
       "word_unique_percent                                            92.8571   \n",
       "punct_percent                                                  14.2857   \n",
       "ip                                                                  []   \n",
       "count_ip                                                             0   \n",
       "link                                                                []   \n",
       "count_links                                                          0   \n",
       "article_id                                                          []   \n",
       "article_id_flag                                                      0   \n",
       "username                                                            []   \n",
       "count_usernames                                                      0   \n",
       "\n",
       "id                                                    0001b41b1c6bb37e  \\\n",
       "comment_text         \" morei cannot make real suggestions improveme...   \n",
       "toxic                                                                0   \n",
       "severe_toxic                                                         0   \n",
       "obscene                                                              0   \n",
       "threat                                                               0   \n",
       "insult                                                               0   \n",
       "identity_hate                                                        0   \n",
       "count_sent                                                           5   \n",
       "count_word                                                         113   \n",
       "count_unique_word                                                   82   \n",
       "count_letters                                                      622   \n",
       "count_punctuations                                                  21   \n",
       "count_words_upper                                                    5   \n",
       "count_words_title                                                    7   \n",
       "count_stopwords                                                     56   \n",
       "mean_word_len                                                  4.48673   \n",
       "word_unique_percent                                            72.5664   \n",
       "punct_percent                                                  18.5841   \n",
       "ip                                                                  []   \n",
       "count_ip                                                             0   \n",
       "link                                                                []   \n",
       "count_links                                                          0   \n",
       "article_id                                                          []   \n",
       "article_id_flag                                                      0   \n",
       "username                                                            []   \n",
       "count_usernames                                                      0   \n",
       "\n",
       "id                                                0001d958c54c6e35  \n",
       "comment_text         , sir , hero . chance remember page that is ?  \n",
       "toxic                                                            0  \n",
       "severe_toxic                                                     0  \n",
       "obscene                                                          0  \n",
       "threat                                                           0  \n",
       "insult                                                           0  \n",
       "identity_hate                                                    0  \n",
       "count_sent                                                       1  \n",
       "count_word                                                      13  \n",
       "count_unique_word                                               13  \n",
       "count_letters                                                   67  \n",
       "count_punctuations                                               5  \n",
       "count_words_upper                                                0  \n",
       "count_words_title                                                2  \n",
       "count_stopwords                                                  5  \n",
       "mean_word_len                                              4.23077  \n",
       "word_unique_percent                                            100  \n",
       "punct_percent                                              38.4615  \n",
       "ip                                                              []  \n",
       "count_ip                                                         0  \n",
       "link                                                            []  \n",
       "count_links                                                      0  \n",
       "article_id                                                      []  \n",
       "article_id_flag                                                  0  \n",
       "username                                                        []  \n",
       "count_usernames                                                  0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x3291 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3642414 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(decode_error='ignore', \n",
    "                norm='l2', \n",
    "                ngram_range=(2, 1), \n",
    "                sublinear_tf=True, \n",
    "                max_df=0.884210526316, \n",
    "                use_idf=True, \n",
    "                smooth_idf=True, \n",
    "                min_df=150,\n",
    "                lowercase=True)\n",
    "tfidf_data = tfidf.fit_transform(data.loc[:, 'comment_text'])\n",
    "tfidf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 3302)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "SELECTED_COLS=['count_sent', 'count_word', 'count_unique_word',\n",
    "       'count_letters', 'count_punctuations', 'count_words_upper',\n",
    "       'count_words_title', 'count_stopwords', 'mean_word_len',\n",
    "       'word_unique_percent', 'punct_percent']\n",
    "\n",
    "train_x = hstack((tfidf_data,data[SELECTED_COLS])).tocsr()\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py\", line 362, in get\n",
      "    return recv()\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/anaconda/envs/py35/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-d139874ce8f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m score = cross_val_score(ExtraTreesClassifier(n_estimators=100, bootstrap=True), \n\u001b[1;32m----> 2\u001b[1;33m                             train_x, data[TARGET], n_jobs=6, cv = 3, verbose=3, scoring='roc_auc')\n\u001b[0m",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                                               fit_params)\n\u001b[1;32m--> 140\u001b[1;33m                       for train, test in cv_iter)\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[1;31m# check if timeout supported in backend future implementation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m'timeout'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score = cross_val_score(ExtraTreesClassifier(n_estimators=100, bootstrap=True), \n",
    "                            train_x, data[TARGET], n_jobs=6, cv = 3, verbose=3, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity_hate\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-b155c65c9e42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     score = cross_val_score(ExtraTreesClassifier(n_estimators=100, bootstrap=True), \n\u001b[1;32m----> 5\u001b[1;33m                             train_x, data[tar].values.ravel(), cv = 10, scoring='roc_auc')\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtot_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                                               fit_params)\n\u001b[1;32m--> 140\u001b[1;33m                       for train, test in cv_iter)\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    324\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 326\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    740\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tot_score = []\n",
    "for tar in TARGET:\n",
    "    print(tar)\n",
    "    score = cross_val_score(ExtraTreesClassifier(n_estimators=100, bootstrap=True), \n",
    "                            train_x, data[tar].values.ravel(), cv = 10, scoring='roc_auc')\n",
    "    print(score)\n",
    "    tot_score.append(np.mean(score))\n",
    "print(np.mean(tot_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('tfidf', TfidfVectorizer()), ('lg', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "space = {\n",
    " 'lg__C': [.0001, .001, .01, .1, 1.0, 10, 100, 1000],\n",
    " 'lg__class_weight': [{1:2, 0:1},{1:3, 0:1}, {1:4, 0:1}, 'balanced', None],\n",
    " 'lg__fit_intercept': [True,False],\n",
    " 'lg__max_iter': [100, 200, 300, 500, 1000],\n",
    " 'lg__penalty': ['l2', 'l1'],\n",
    " 'lg__random_state': [234],\n",
    " 'lg__tol': [0.0001, .001, .01],\n",
    " 'lg__warm_start': [False,True],\n",
    " #'tfidf__analyzer': 'word',\n",
    "# 'tfidf__binary': [False,True],\n",
    " 'tfidf__decode_error': ['ignore'],\n",
    " #'tfidf__input': 'content',\n",
    " 'tfidf__lowercase': [False,True],\n",
    " 'tfidf__max_df': list(np.linspace(0.8, 1.0, 20)),\n",
    "# 'tfidf__max_features': [10000, None], may be it's false\n",
    " 'tfidf__min_df': [1, 2, 3],\n",
    " 'tfidf__ngram_range': [(1, 1), (2, 1), (3, 1), (2, 2), (3, 2)], #(3, 3), (4, 1)\n",
    " 'tfidf__norm': ['l2','l1', None],\n",
    " 'tfidf__smooth_idf': [False,True],\n",
    " #'tfidf__stop_words': None,\n",
    " #'tfidf__strip_accents': None,\n",
    " 'tfidf__sublinear_tf': [False,True],\n",
    " #'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    " 'tfidf__use_idf': [False,True]\n",
    " #'tfidf__vocabulary': None\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "[CV]  lg__tol=0.001, tfidf__ngram_range=(3, 1), lg__penalty=l2, tfidf__norm=l1, tfidf__min_df=1, tfidf__smooth_idf=False, tfidf__use_idf=True, lg__max_iter=200, lg__C=1000, tfidf__max_df=0.831578947368, tfidf__sublinear_tf=True, lg__fit_intercept=True, lg__class_weight={0: 1, 1: 2}, tfidf__lowercase=False, lg__warm_start=True, tfidf__decode_error=ignore, lg__random_state=234, score=-0.048586, total= 1.3min\n",
    "[CV] lg__tol=0.001, tfidf__ngram_range=(3, 2), lg__penalty=l1, tfidf__norm=None, tfidf__min_df=50, tfidf__smooth_idf=True, tfidf__use_idf=True, lg__max_iter=1000, lg__C=0.01, tfidf__max_df=0.831578947368, tfidf__sublinear_tf=True, lg__fit_intercept=False, lg__class_weight={0: 1, 1: 3}, tfidf__lowercase=False, lg__warm_start=False, tfidf__decode_error=ignore, lg__random_state=234 \n",
    "[CV]  lg__tol=0.001, tfidf__ngram_range=(3, 1), lg__penalty=l2, tfidf__norm=l1, tfidf__min_df=1, tfidf__smooth_idf=False, tfidf__use_idf=True, lg__max_iter=200, lg__C=1000, tfidf__max_df=0.831578947368, tfidf__sublinear_tf=True, lg__fit_intercept=True, lg__class_weight={0: 1, 1: 2}, tfidf__lowercase=False, lg__warm_start=True, tfidf__decode_error=ignore, lg__random_state=234, score=-0.046259, total=  58.4s\n",
    "[CV] lg__tol=0.001, tfidf__ngram_range=(3, 2), lg__penalty=l1, tfidf__norm=None, tfidf__min_df=50, tfidf__smooth_idf=True, tfidf__use_idf=True, lg__max_iter=1000, lg__C=0.01, tfidf__max_df=0.831578947368, tfidf__sublinear_tf=True, lg__fit_intercept=False, lg__class_weight={0: 1, 1: 3}, tfidf__lowercase=False, lg__warm_start=False, tfidf__decode_error=ignore, lg__random_state=234 \n",
    "\n",
    "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/linear_model/base.py:352: RuntimeWarning: overflow encountered in exp\n",
    "  np.exp(prob, prob)\n",
    "\n",
    "[CV]  lg__tol=0.01, tfidf__ngram_range=(2, 1), lg__penalty=l1, tfidf__norm=None, tfidf__min_df=50, tfidf__smooth_idf=False, tfidf__use_idf=False, lg__max_iter=1000, lg__C=100, tfidf__max_df=0.978947368421, tfidf__sublinear_tf=False, lg__fit_intercept=False, lg__class_weight={0: 1, 1: 4}, tfidf__lowercase=False, lg__warm_start=False, tfidf__decode_error=ignore, lg__random_state=234, score=-0.316191, total=28.3min\n",
    "[CV] lg__tol=0.01, tfidf__ngram_range=(2, 1), lg__penalty=l2, tfidf__norm=l2, tfidf__min_df=50, tfidf__smooth_idf=True, tfidf__use_idf=True, lg__max_iter=200, lg__C=1.0, tfidf__max_df=0.884210526316, tfidf__sublinear_tf=False, lg__fit_intercept=False, lg__class_weight={0: 1, 1: 4}, tfidf__lowercase=True, lg__warm_start=False, tfidf__decode_error=ignore, lg__random_state=234 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity_hate\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "[CV] lg__tol=0.01, tfidf__ngram_range=(2, 1), lg__penalty=l1, tfidf__norm=None, tfidf__min_df=50, tfidf__smooth_idf=False, tfidf__use_idf=False, lg__max_iter=1000, lg__C=100, tfidf__max_df=0.978947368421, tfidf__sublinear_tf=False, lg__fit_intercept=False, lg__class_weight={0: 1, 1: 4}, tfidf__lowercase=False, lg__warm_start=False, tfidf__decode_error=ignore, lg__random_state=234 \n",
      "[CV] lg__tol=0.01, tfidf__ngram_range=(2, 1), lg__penalty=l1, tfidf__norm=None, tfidf__min_df=50, tfidf__smooth_idf=False, tfidf__use_idf=False, lg__max_iter=1000, lg__C=100, tfidf__max_df=0.978947368421, tfidf__sublinear_tf=False, lg__fit_intercept=False, lg__class_weight={0: 1, 1: 4}, tfidf__lowercase=False, lg__warm_start=False, tfidf__decode_error=ignore, lg__random_state=234 \n",
      "[CV] lg__tol=0.01, tfidf__ngram_range=(2, 1), lg__penalty=l1, tfidf__norm=None, tfidf__min_df=50, tfidf__smooth_idf=False, tfidf__use_idf=False, lg__max_iter=1000, lg__C=100, tfidf__max_df=0.978947368421, tfidf__sublinear_tf=False, lg__fit_intercept=False, lg__class_weight={0: 1, 1: 4}, tfidf__lowercase=False, lg__warm_start=False, tfidf__decode_error=ignore, lg__random_state=234 \n"
     ]
    },
    {
     "ename": "JoblibAttributeError",
     "evalue": "JoblibAttributeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7f4740b8fc90, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda/envs/py35/lib/python3.5/site-packages/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda/en.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f4740b8fc90, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda/envs/py35/lib/python3.5/site-packages/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda/en.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\nscore = []\\nrnd = RandomizedSearchCV(pipe,.../grid_search_'+tar+'_.csv', sep=';', index=False)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 22, 5, 17, 42, 37995, tzinfo=datetime.timezone.utc), 'msg_id': 'C4E73FE09D4249A985C9CE1EDB59B06C', 'msg_type': 'execute_request', 'session': '383C5FB97A0D42A6B38CE9AAA5853799', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C4E73FE09D4249A985C9CE1EDB59B06C', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'383C5FB97A0D42A6B38CE9AAA5853799']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\nscore = []\\nrnd = RandomizedSearchCV(pipe,.../grid_search_'+tar+'_.csv', sep=';', index=False)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 22, 5, 17, 42, 37995, tzinfo=datetime.timezone.utc), 'msg_id': 'C4E73FE09D4249A985C9CE1EDB59B06C', 'msg_type': 'execute_request', 'session': '383C5FB97A0D42A6B38CE9AAA5853799', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C4E73FE09D4249A985C9CE1EDB59B06C', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'383C5FB97A0D42A6B38CE9AAA5853799'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\nscore = []\\nrnd = RandomizedSearchCV(pipe,.../grid_search_'+tar+'_.csv', sep=';', index=False)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 22, 5, 17, 42, 37995, tzinfo=datetime.timezone.utc), 'msg_id': 'C4E73FE09D4249A985C9CE1EDB59B06C', 'msg_type': 'execute_request', 'session': '383C5FB97A0D42A6B38CE9AAA5853799', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C4E73FE09D4249A985C9CE1EDB59B06C', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"%%time\\nscore = []\\nrnd = RandomizedSearchCV(pipe,.../grid_search_'+tar+'_.csv', sep=';', index=False)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"%%time\\nscore = []\\nrnd = RandomizedSearchCV(pipe,.../grid_search_'+tar+'_.csv', sep=';', index=False)\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"%%time\\nscore = []\\nrnd = RandomizedSearchCV(pipe,.../grid_search_'+tar+'_.csv', sep=';', index=False)\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"%%time\\nscore = []\\nrnd = RandomizedSearchCV(pipe,.../grid_search_'+tar+'_.csv', sep=';', index=False)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"%%time\\nscore = []\\nrnd = RandomizedSearchCV(pipe,.../grid_search_'+tar+'_.csv', sep=';', index=False)\", store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-13-26803c1f7666>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n   2830                 code = compiler(mod, cell_name, \"single\")\n-> 2831                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f46eaf61810, file \"<ipython-input-13-26803c1f7666>\", line 1>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2832                     return True\n   2833 \n   2834             # Flush softspace\n   2835             if softspace(sys.stdout, 0):\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f46eaf61810, file \"<ipython-input-13-26803c1f7666>\", line 1>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f46eaf61810, file \"<ipython-input-13-26803c1f7666>\", line 1>\n        self.user_global_ns = {'AMLHelpers': <class '__main__.AMLHelpers'>, 'Capturing': <class '__main__.Capturing'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.feature_extract...edict, RandomizedSearchCV\\n\\nfrom gc import collect', \"TARGET = ['identity_hate', 'insult', 'obscene','severe_toxic', 'threat', 'toxic']\", \"data =  pd.read_csv('data/train.csv', sep=',', i...na(0, inplace=True)\\nprint(data.shape)\\ndata.head()\", \"pipe = Pipeline([('tfidf', TfidfVectorizer()), ('lg', LogisticRegression())])\", \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", \"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', \"pipe = Pipeline([('tfidf', TfidfVectorizer(input = 'file')), ('lg', LogisticRegression())])\", \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")'], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Magics': <class 'IPython.core.magic.Magics'>, 'Out': {3:                                                 ...01b41b1c6bb37e    1.0  \n0001d958c54c6e35    1.0  }, 'PYTHON_2': False, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n        self.user_ns = {'AMLHelpers': <class '__main__.AMLHelpers'>, 'Capturing': <class '__main__.Capturing'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.feature_extract...edict, RandomizedSearchCV\\n\\nfrom gc import collect', \"TARGET = ['identity_hate', 'insult', 'obscene','severe_toxic', 'threat', 'toxic']\", \"data =  pd.read_csv('data/train.csv', sep=',', i...na(0, inplace=True)\\nprint(data.shape)\\ndata.head()\", \"pipe = Pipeline([('tfidf', TfidfVectorizer()), ('lg', LogisticRegression())])\", \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", \"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', \"pipe = Pipeline([('tfidf', TfidfVectorizer(input = 'file')), ('lg', LogisticRegression())])\", \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")'], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Magics': <class 'IPython.core.magic.Magics'>, 'Out': {3:                                                 ...01b41b1c6bb37e    1.0  \n0001d958c54c6e35    1.0  }, 'PYTHON_2': False, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\n/home/cerdgio/notebooks/Toxic_comp/<ipython-input-13-26803c1f7666> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 get_ipython().run_cell_magic('time', '', \"score = []\\nrnd = RandomizedSearchCV(pipe, param_distributions=space, n_iter=200, scoring='neg_log_loss', \\n                       cv = 5, verbose=3, random_state=234, n_jobs = -1)\\nfor i, tar in enumerate(TARGET):\\n    print(tar)\\n    score.append(rnd.fit(data.loc[data.train==1, 'comment_text'], data.loc[data.train==1, tar].values))\\n    pd.DataFrame(score[i].cv_results_).to_csv('metrics/grid_search_'+tar+'_.csv', sep=';', index=False)\")\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name='time', line='', cell=\"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\")\n   2115             # This will need to be updated if the internal calling logic gets\n   2116             # refactored, or else we'll be expanding the wrong variables.\n   2117             stack_depth = 2\n   2118             magic_arg_s = self.var_expand(line, stack_depth)\n   2119             with self.builtin_trap:\n-> 2120                 result = fn(magic_arg_s, cell)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        magic_arg_s = ''\n        cell = \"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\"\n   2121             return result\n   2122 \n   2123     def find_line_magic(self, magic_name):\n   2124         \"\"\"Find and return a line magic by name.\n\n...........................................................................\n/home/cerdgio/notebooks/Toxic_comp/<decorator-gen-60> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell=\"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\", local_ns=None)\n      1 \n----> 2 \n      3 \n      4 \n      5 \n      6 \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/magic.py in <lambda>(f=<function ExecutionMagics.time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, '', \"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\", None), **k={})\n    188     validate_type(magic_kind)\n    189 \n    190     # This is a closure to capture the magic_kind.  We could also use a class,\n    191     # but it's overkill for just that one bit of state.\n    192     def magic_deco(arg):\n--> 193         call = lambda f, *a, **k: f(*a, **k)\n        f = <function ExecutionMagics.time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, '', \"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\", None)\n        k = {}\n    194 \n    195         if callable(arg):\n    196             # \"Naked\" decorator call (just @foo, no args)\n    197             func = arg\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/magics/execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell=\"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\", local_ns=None)\n   1172             st = clock2()\n   1173             out = eval(code, glob, local_ns)\n   1174             end = clock2()\n   1175         else:\n   1176             st = clock2()\n-> 1177             exec(code, glob, local_ns)\n        code = <code object <module> at 0x7f46eaf61a50, file \"<timed exec>\", line 1>\n        glob = {'AMLHelpers': <class '__main__.AMLHelpers'>, 'Capturing': <class '__main__.Capturing'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.feature_extract...edict, RandomizedSearchCV\\n\\nfrom gc import collect', \"TARGET = ['identity_hate', 'insult', 'obscene','severe_toxic', 'threat', 'toxic']\", \"data =  pd.read_csv('data/train.csv', sep=',', i...na(0, inplace=True)\\nprint(data.shape)\\ndata.head()\", \"pipe = Pipeline([('tfidf', TfidfVectorizer()), ('lg', LogisticRegression())])\", \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", \"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', \"pipe = Pipeline([('tfidf', TfidfVectorizer(input = 'file')), ('lg', LogisticRegression())])\", \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")'], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Magics': <class 'IPython.core.magic.Magics'>, 'Out': {3:                                                 ...01b41b1c6bb37e    1.0  \n0001d958c54c6e35    1.0  }, 'PYTHON_2': False, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n        local_ns = None\n   1178             end = clock2()\n   1179             out = None\n   1180         wall_end = wtime()\n   1181         # Compute actual times and report\n\n...........................................................................\n/home/cerdgio/notebooks/Toxic_comp/<timed exec> in <module>()\n      1 \n      2 \n      3 \n      4 \n      5 \n----> 6 \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=5, error_score='raise',\n  ...in_score=True, scoring='neg_log_loss', verbose=3), X=id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object, y=array([ 0.,  0.,  0., ...,  0.,  0.,  0.]), groups=None)\n   1185             train/test set.\n   1186         \"\"\"\n   1187         sampled_params = ParameterSampler(self.param_distributions,\n   1188                                           self.n_iter,\n   1189                                           random_state=self.random_state)\n-> 1190         return self._fit(X, y, groups, sampled_params)\n        self._fit = <bound method BaseSearchCV._fit of RandomizedSea...n_score=True, scoring='neg_log_loss', verbose=3)>\n        X = id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object\n        y = array([ 0.,  0.,  0., ...,  0.,  0.,  0.])\n        groups = None\n        sampled_params = <sklearn.model_selection._search.ParameterSampler object>\n   1191 \n   1192 \n   1193 \n   1194 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_search.py in _fit(self=RandomizedSearchCV(cv=5, error_score='raise',\n  ...in_score=True, scoring='neg_log_loss', verbose=3), X=id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object, y=array([ 0.,  0.,  0., ...,  0.,  0.,  0.]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterSampler object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterSampler object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nAttributeError                                     Mon Jan 22 05:17:42 2018\nPID: 84365                     Python 3.5.2: /anaconda/envs/py35/bin/python\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object, memmap([ 0.,  0.,  0., ...,  0.,  0.,  0.]), make_scorer(log_loss, greater_is_better=False, needs_proba=True), array([ 31658,  31916,  31917, ..., 159568, 159569, 159570]), array([    0,     1,     2, ..., 31913, 31914, 31915]), 3, {'lg__C': 100, 'lg__class_weight': {0: 1, 1: 4}, 'lg__fit_intercept': False, 'lg__max_iter': 1000, 'lg__penalty': 'l1', 'lg__random_state': 234, 'lg__tol': 0.01, 'lg__warm_start': False, 'tfidf__decode_error': 'ignore', 'tfidf__lowercase': False, ...}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object, memmap([ 0.,  0.,  0., ...,  0.,  0.,  0.]), make_scorer(log_loss, greater_is_better=False, needs_proba=True), array([ 31658,  31916,  31917, ..., 159568, 159569, 159570]), array([    0,     1,     2, ..., 31913, 31914, 31915]), 3, {'lg__C': 100, 'lg__class_weight': {0: 1, 1: 4}, 'lg__fit_intercept': False, 'lg__max_iter': 1000, 'lg__penalty': 'l1', 'lg__random_state': 234, 'lg__tol': 0.01, 'lg__warm_start': False, 'tfidf__decode_error': 'ignore', 'tfidf__lowercase': False, ...})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), X=id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object, y=memmap([ 0.,  0.,  0., ...,  0.,  0.,  0.]), scorer=make_scorer(log_loss, greater_is_better=False, needs_proba=True), train=array([ 31658,  31916,  31917, ..., 159568, 159569, 159570]), test=array([    0,     1,     2, ..., 31913, 31914, 31915]), verbose=3, parameters={'lg__C': 100, 'lg__class_weight': {0: 1, 1: 4}, 'lg__fit_intercept': False, 'lg__max_iter': 1000, 'lg__penalty': 'l1', 'lg__random_state': 234, 'lg__tol': 0.01, 'lg__warm_start': False, 'tfidf__decode_error': 'ignore', 'tfidf__lowercase': False, ...}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...near', tol=0.01, verbose=0, warm_start=False))])>\n        X_train = id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object\n        y_train = memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), X=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, y=memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.]), **fit_params={})\n    263         Returns\n    264         -------\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n--> 268         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(steps=[(...near', tol=0.01, verbose=0, warm_start=False))])>\n        X = id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object\n        y = memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.])\n    269         if self._final_estimator is not None:\n    270             self._final_estimator.fit(Xt, y, **fit_params)\n    271         return self\n    272 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), X=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, y=memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.]), **fit_params={})\n    229         Xt = X\n    230         for name, transform in self.steps[:-1]:\n    231             if transform is None:\n    232                 pass\n    233             elif hasattr(transform, \"fit_transform\"):\n--> 234                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt = id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object\n        transform.fit_transform = <bound method TfidfVectorizer.fit_transform of T... tokenizer=None, use_idf=False, vocabulary=None)>\n        y = memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.])\n        fit_params_steps = {'lg': {}, 'tfidf': {}}\n        name = 'tfidf'\n    235             else:\n    236                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    237                               .transform(Xt)\n    238         if self._final_estimator is None:\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=TfidfVectorizer(analyzer='word', binary=False, d...  tokenizer=None, use_idf=False, vocabulary=None), raw_documents=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, y=memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.]))\n   1347         Returns\n   1348         -------\n   1349         X : sparse matrix, [n_samples, n_features]\n   1350             Tf-idf-weighted document-term matrix.\n   1351         \"\"\"\n-> 1352         X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n        X = undefined\n        self.fit_transform = <bound method TfidfVectorizer.fit_transform of T... tokenizer=None, use_idf=False, vocabulary=None)>\n        raw_documents = id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object\n   1353         self._tfidf.fit(X)\n   1354         # X is already a transformed view of raw_documents so\n   1355         # we set copy to False\n   1356         return self._tfidf.transform(X, copy=False)\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=TfidfVectorizer(analyzer='word', binary=False, d...  tokenizer=None, use_idf=False, vocabulary=None), raw_documents=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, y=None)\n    834         max_df = self.max_df\n    835         min_df = self.min_df\n    836         max_features = self.max_features\n    837 \n    838         vocabulary, X = self._count_vocab(raw_documents,\n--> 839                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    840 \n    841         if self.binary:\n    842             X.data.fill(1)\n    843 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in _count_vocab(self=TfidfVectorizer(analyzer='word', binary=False, d...  tokenizer=None, use_idf=False, vocabulary=None), raw_documents=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, fixed_vocab=False)\n    757         indptr = _make_int_array()\n    758         values = _make_int_array()\n    759         indptr.append(0)\n    760         for doc in raw_documents:\n    761             feature_counter = {}\n--> 762             for feature in analyze(doc):\n        feature = undefined\n        analyze = <function VectorizerMixin.build_analyzer.<locals>.<lambda>>\n        doc = \"Wait, you are female and black..! That's disconcerting...\"\n    763                 try:\n    764                     feature_idx = vocabulary[feature]\n    765                     if feature_idx not in feature_counter:\n    766                         feature_counter[feature_idx] = 1\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in <lambda>(doc=\"Wait, you are female and black..! That's disconcerting...\")\n    236         elif self.analyzer == 'word':\n    237             stop_words = self.get_stop_words()\n    238             tokenize = self.build_tokenizer()\n    239 \n    240             return lambda doc: self._word_ngrams(\n--> 241                 tokenize(preprocess(self.decode(doc))), stop_words)\n        doc = \"Wait, you are female and black..! That's disconcerting...\"\n    242 \n    243         else:\n    244             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n    245                              self.analyzer)\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in decode(self=TfidfVectorizer(analyzer='word', binary=False, d...  tokenizer=None, use_idf=False, vocabulary=None), doc=\"Wait, you are female and black..! That's disconcerting...\")\n    110         if self.input == 'filename':\n    111             with open(doc, 'rb') as fh:\n    112                 doc = fh.read()\n    113 \n    114         elif self.input == 'file':\n--> 115             doc = doc.read()\n        doc = \"Wait, you are female and black..! That's disconcerting...\"\n        doc.read = undefined\n    116 \n    117         if isinstance(doc, bytes):\n    118             doc = doc.decode(self.encoding, self.decode_error)\n    119 \n\nAttributeError: 'str' object has no attribute 'read'\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\", line 238, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/pipeline.py\", line 268, in fit\n    Xt, fit_params = self._fit(X, y, **fit_params)\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/pipeline.py\", line 234, in _fit\n    Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py\", line 1352, in fit_transform\n    X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py\", line 839, in fit_transform\n    self.fixed_vocabulary_)\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py\", line 762, in _count_vocab\n    for feature in analyze(doc):\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py\", line 241, in <lambda>\n    tokenize(preprocess(self.decode(doc))), stop_words)\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py\", line 115, in decode\n    doc = doc.read()\nAttributeError: 'str' object has no attribute 'read'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nAttributeError                                     Mon Jan 22 05:17:42 2018\nPID: 84365                     Python 3.5.2: /anaconda/envs/py35/bin/python\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object, memmap([ 0.,  0.,  0., ...,  0.,  0.,  0.]), make_scorer(log_loss, greater_is_better=False, needs_proba=True), array([ 31658,  31916,  31917, ..., 159568, 159569, 159570]), array([    0,     1,     2, ..., 31913, 31914, 31915]), 3, {'lg__C': 100, 'lg__class_weight': {0: 1, 1: 4}, 'lg__fit_intercept': False, 'lg__max_iter': 1000, 'lg__penalty': 'l1', 'lg__random_state': 234, 'lg__tol': 0.01, 'lg__warm_start': False, 'tfidf__decode_error': 'ignore', 'tfidf__lowercase': False, ...}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object, memmap([ 0.,  0.,  0., ...,  0.,  0.,  0.]), make_scorer(log_loss, greater_is_better=False, needs_proba=True), array([ 31658,  31916,  31917, ..., 159568, 159569, 159570]), array([    0,     1,     2, ..., 31913, 31914, 31915]), 3, {'lg__C': 100, 'lg__class_weight': {0: 1, 1: 4}, 'lg__fit_intercept': False, 'lg__max_iter': 1000, 'lg__penalty': 'l1', 'lg__random_state': 234, 'lg__tol': 0.01, 'lg__warm_start': False, 'tfidf__decode_error': 'ignore', 'tfidf__lowercase': False, ...})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), X=id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object, y=memmap([ 0.,  0.,  0., ...,  0.,  0.,  0.]), scorer=make_scorer(log_loss, greater_is_better=False, needs_proba=True), train=array([ 31658,  31916,  31917, ..., 159568, 159569, 159570]), test=array([    0,     1,     2, ..., 31913, 31914, 31915]), verbose=3, parameters={'lg__C': 100, 'lg__class_weight': {0: 1, 1: 4}, 'lg__fit_intercept': False, 'lg__max_iter': 1000, 'lg__penalty': 'l1', 'lg__random_state': 234, 'lg__tol': 0.01, 'lg__warm_start': False, 'tfidf__decode_error': 'ignore', 'tfidf__lowercase': False, ...}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...near', tol=0.01, verbose=0, warm_start=False))])>\n        X_train = id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object\n        y_train = memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), X=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, y=memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.]), **fit_params={})\n    263         Returns\n    264         -------\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n--> 268         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(steps=[(...near', tol=0.01, verbose=0, warm_start=False))])>\n        X = id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object\n        y = memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.])\n    269         if self._final_estimator is not None:\n    270             self._final_estimator.fit(Xt, y, **fit_params)\n    271         return self\n    272 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), X=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, y=memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.]), **fit_params={})\n    229         Xt = X\n    230         for name, transform in self.steps[:-1]:\n    231             if transform is None:\n    232                 pass\n    233             elif hasattr(transform, \"fit_transform\"):\n--> 234                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt = id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object\n        transform.fit_transform = <bound method TfidfVectorizer.fit_transform of T... tokenizer=None, use_idf=False, vocabulary=None)>\n        y = memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.])\n        fit_params_steps = {'lg': {}, 'tfidf': {}}\n        name = 'tfidf'\n    235             else:\n    236                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    237                               .transform(Xt)\n    238         if self._final_estimator is None:\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=TfidfVectorizer(analyzer='word', binary=False, d...  tokenizer=None, use_idf=False, vocabulary=None), raw_documents=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, y=memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.]))\n   1347         Returns\n   1348         -------\n   1349         X : sparse matrix, [n_samples, n_features]\n   1350             Tf-idf-weighted document-term matrix.\n   1351         \"\"\"\n-> 1352         X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n        X = undefined\n        self.fit_transform = <bound method TfidfVectorizer.fit_transform of T... tokenizer=None, use_idf=False, vocabulary=None)>\n        raw_documents = id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object\n   1353         self._tfidf.fit(X)\n   1354         # X is already a transformed view of raw_documents so\n   1355         # we set copy to False\n   1356         return self._tfidf.transform(X, copy=False)\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=TfidfVectorizer(analyzer='word', binary=False, d...  tokenizer=None, use_idf=False, vocabulary=None), raw_documents=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, y=None)\n    834         max_df = self.max_df\n    835         min_df = self.min_df\n    836         max_features = self.max_features\n    837 \n    838         vocabulary, X = self._count_vocab(raw_documents,\n--> 839                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    840 \n    841         if self.binary:\n    842             X.data.fill(1)\n    843 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in _count_vocab(self=TfidfVectorizer(analyzer='word', binary=False, d...  tokenizer=None, use_idf=False, vocabulary=None), raw_documents=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, fixed_vocab=False)\n    757         indptr = _make_int_array()\n    758         values = _make_int_array()\n    759         indptr.append(0)\n    760         for doc in raw_documents:\n    761             feature_counter = {}\n--> 762             for feature in analyze(doc):\n        feature = undefined\n        analyze = <function VectorizerMixin.build_analyzer.<locals>.<lambda>>\n        doc = \"Wait, you are female and black..! That's disconcerting...\"\n    763                 try:\n    764                     feature_idx = vocabulary[feature]\n    765                     if feature_idx not in feature_counter:\n    766                         feature_counter[feature_idx] = 1\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in <lambda>(doc=\"Wait, you are female and black..! That's disconcerting...\")\n    236         elif self.analyzer == 'word':\n    237             stop_words = self.get_stop_words()\n    238             tokenize = self.build_tokenizer()\n    239 \n    240             return lambda doc: self._word_ngrams(\n--> 241                 tokenize(preprocess(self.decode(doc))), stop_words)\n        doc = \"Wait, you are female and black..! That's disconcerting...\"\n    242 \n    243         else:\n    244             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n    245                              self.analyzer)\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in decode(self=TfidfVectorizer(analyzer='word', binary=False, d...  tokenizer=None, use_idf=False, vocabulary=None), doc=\"Wait, you are female and black..! That's disconcerting...\")\n    110         if self.input == 'filename':\n    111             with open(doc, 'rb') as fh:\n    112                 doc = fh.read()\n    113 \n    114         elif self.input == 'file':\n--> 115             doc = doc.read()\n        doc = \"Wait, you are female and black..! That's disconcerting...\"\n        doc.read = undefined\n    116 \n    117         if isinstance(doc, bytes):\n    118             doc = doc.decode(self.encoding, self.decode_error)\n    119 \n\nAttributeError: 'str' object has no attribute 'read'\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    681\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m'timeout'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nAttributeError                                     Mon Jan 22 05:17:42 2018\nPID: 84365                     Python 3.5.2: /anaconda/envs/py35/bin/python\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object, memmap([ 0.,  0.,  0., ...,  0.,  0.,  0.]), make_scorer(log_loss, greater_is_better=False, needs_proba=True), array([ 31658,  31916,  31917, ..., 159568, 159569, 159570]), array([    0,     1,     2, ..., 31913, 31914, 31915]), 3, {'lg__C': 100, 'lg__class_weight': {0: 1, 1: 4}, 'lg__fit_intercept': False, 'lg__max_iter': 1000, 'lg__penalty': 'l1', 'lg__random_state': 234, 'lg__tol': 0.01, 'lg__warm_start': False, 'tfidf__decode_error': 'ignore', 'tfidf__lowercase': False, ...}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object, memmap([ 0.,  0.,  0., ...,  0.,  0.,  0.]), make_scorer(log_loss, greater_is_better=False, needs_proba=True), array([ 31658,  31916,  31917, ..., 159568, 159569, 159570]), array([    0,     1,     2, ..., 31913, 31914, 31915]), 3, {'lg__C': 100, 'lg__class_weight': {0: 1, 1: 4}, 'lg__fit_intercept': False, 'lg__max_iter': 1000, 'lg__penalty': 'l1', 'lg__random_state': 234, 'lg__tol': 0.01, 'lg__warm_start': False, 'tfidf__decode_error': 'ignore', 'tfidf__lowercase': False, ...})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), X=id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object, y=memmap([ 0.,  0.,  0., ...,  0.,  0.,  0.]), scorer=make_scorer(log_loss, greater_is_better=False, needs_proba=True), train=array([ 31658,  31916,  31917, ..., 159568, 159569, 159570]), test=array([    0,     1,     2, ..., 31913, 31914, 31915]), verbose=3, parameters={'lg__C': 100, 'lg__class_weight': {0: 1, 1: 4}, 'lg__fit_intercept': False, 'lg__max_iter': 1000, 'lg__penalty': 'l1', 'lg__random_state': 234, 'lg__tol': 0.01, 'lg__warm_start': False, 'tfidf__decode_error': 'ignore', 'tfidf__lowercase': False, ...}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...near', tol=0.01, verbose=0, warm_start=False))])>\n        X_train = id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object\n        y_train = memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), X=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, y=memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.]), **fit_params={})\n    263         Returns\n    264         -------\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n--> 268         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(steps=[(...near', tol=0.01, verbose=0, warm_start=False))])>\n        X = id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object\n        y = memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.])\n    269         if self._final_estimator is not None:\n    270             self._final_estimator.fit(Xt, y, **fit_params)\n    271         return self\n    272 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), X=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, y=memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.]), **fit_params={})\n    229         Xt = X\n    230         for name, transform in self.steps[:-1]:\n    231             if transform is None:\n    232                 pass\n    233             elif hasattr(transform, \"fit_transform\"):\n--> 234                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt = id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object\n        transform.fit_transform = <bound method TfidfVectorizer.fit_transform of T... tokenizer=None, use_idf=False, vocabulary=None)>\n        y = memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.])\n        fit_params_steps = {'lg': {}, 'tfidf': {}}\n        name = 'tfidf'\n    235             else:\n    236                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    237                               .transform(Xt)\n    238         if self._final_estimator is None:\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=TfidfVectorizer(analyzer='word', binary=False, d...  tokenizer=None, use_idf=False, vocabulary=None), raw_documents=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, y=memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.]))\n   1347         Returns\n   1348         -------\n   1349         X : sparse matrix, [n_samples, n_features]\n   1350             Tf-idf-weighted document-term matrix.\n   1351         \"\"\"\n-> 1352         X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n        X = undefined\n        self.fit_transform = <bound method TfidfVectorizer.fit_transform of T... tokenizer=None, use_idf=False, vocabulary=None)>\n        raw_documents = id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object\n   1353         self._tfidf.fit(X)\n   1354         # X is already a transformed view of raw_documents so\n   1355         # we set copy to False\n   1356         return self._tfidf.transform(X, copy=False)\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=TfidfVectorizer(analyzer='word', binary=False, d...  tokenizer=None, use_idf=False, vocabulary=None), raw_documents=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, y=None)\n    834         max_df = self.max_df\n    835         min_df = self.min_df\n    836         max_features = self.max_features\n    837 \n    838         vocabulary, X = self._count_vocab(raw_documents,\n--> 839                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    840 \n    841         if self.binary:\n    842             X.data.fill(1)\n    843 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in _count_vocab(self=TfidfVectorizer(analyzer='word', binary=False, d...  tokenizer=None, use_idf=False, vocabulary=None), raw_documents=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, fixed_vocab=False)\n    757         indptr = _make_int_array()\n    758         values = _make_int_array()\n    759         indptr.append(0)\n    760         for doc in raw_documents:\n    761             feature_counter = {}\n--> 762             for feature in analyze(doc):\n        feature = undefined\n        analyze = <function VectorizerMixin.build_analyzer.<locals>.<lambda>>\n        doc = \"Wait, you are female and black..! That's disconcerting...\"\n    763                 try:\n    764                     feature_idx = vocabulary[feature]\n    765                     if feature_idx not in feature_counter:\n    766                         feature_counter[feature_idx] = 1\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in <lambda>(doc=\"Wait, you are female and black..! That's disconcerting...\")\n    236         elif self.analyzer == 'word':\n    237             stop_words = self.get_stop_words()\n    238             tokenize = self.build_tokenizer()\n    239 \n    240             return lambda doc: self._word_ngrams(\n--> 241                 tokenize(preprocess(self.decode(doc))), stop_words)\n        doc = \"Wait, you are female and black..! That's disconcerting...\"\n    242 \n    243         else:\n    244             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n    245                              self.analyzer)\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in decode(self=TfidfVectorizer(analyzer='word', binary=False, d...  tokenizer=None, use_idf=False, vocabulary=None), doc=\"Wait, you are female and black..! That's disconcerting...\")\n    110         if self.input == 'filename':\n    111             with open(doc, 'rb') as fh:\n    112                 doc = fh.read()\n    113 \n    114         elif self.input == 'file':\n--> 115             doc = doc.read()\n        doc = \"Wait, you are female and black..! That's disconcerting...\"\n        doc.read = undefined\n    116 \n    117         if isinstance(doc, bytes):\n    118             doc = doc.decode(self.encoding, self.decode_error)\n    119 \n\nAttributeError: 'str' object has no attribute 'read'\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-26803c1f7666>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"score = []\\nrnd = RandomizedSearchCV(pipe, param_distributions=space, n_iter=200, scoring='neg_log_loss', \\n                       cv = 5, verbose=3, random_state=234, n_jobs = -1)\\nfor i, tar in enumerate(TARGET):\\n    print(tar)\\n    score.append(rnd.fit(data.loc[data.train==1, 'comment_text'], data.loc[data.train==1, tar].values))\\n    pd.DataFrame(score[i].cv_results_).to_csv('metrics/grid_search_'+tar+'_.csv', sep=';', index=False)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2120\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1188\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m                                           random_state=self.random_state)\n\u001b[1;32m-> 1190\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampled_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[0;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m--> 564\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibAttributeError\u001b[0m: JoblibAttributeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7f4740b8fc90, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda/envs/py35/lib/python3.5/site-packages/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda/en.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f4740b8fc90, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda/envs/py35/lib/python3.5/site-packages/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda/en.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\nscore = []\\nrnd = RandomizedSearchCV(pipe,.../grid_search_'+tar+'_.csv', sep=';', index=False)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 22, 5, 17, 42, 37995, tzinfo=datetime.timezone.utc), 'msg_id': 'C4E73FE09D4249A985C9CE1EDB59B06C', 'msg_type': 'execute_request', 'session': '383C5FB97A0D42A6B38CE9AAA5853799', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C4E73FE09D4249A985C9CE1EDB59B06C', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'383C5FB97A0D42A6B38CE9AAA5853799']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\nscore = []\\nrnd = RandomizedSearchCV(pipe,.../grid_search_'+tar+'_.csv', sep=';', index=False)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 22, 5, 17, 42, 37995, tzinfo=datetime.timezone.utc), 'msg_id': 'C4E73FE09D4249A985C9CE1EDB59B06C', 'msg_type': 'execute_request', 'session': '383C5FB97A0D42A6B38CE9AAA5853799', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C4E73FE09D4249A985C9CE1EDB59B06C', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'383C5FB97A0D42A6B38CE9AAA5853799'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"%%time\\nscore = []\\nrnd = RandomizedSearchCV(pipe,.../grid_search_'+tar+'_.csv', sep=';', index=False)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 22, 5, 17, 42, 37995, tzinfo=datetime.timezone.utc), 'msg_id': 'C4E73FE09D4249A985C9CE1EDB59B06C', 'msg_type': 'execute_request', 'session': '383C5FB97A0D42A6B38CE9AAA5853799', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C4E73FE09D4249A985C9CE1EDB59B06C', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"%%time\\nscore = []\\nrnd = RandomizedSearchCV(pipe,.../grid_search_'+tar+'_.csv', sep=';', index=False)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"%%time\\nscore = []\\nrnd = RandomizedSearchCV(pipe,.../grid_search_'+tar+'_.csv', sep=';', index=False)\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"%%time\\nscore = []\\nrnd = RandomizedSearchCV(pipe,.../grid_search_'+tar+'_.csv', sep=';', index=False)\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"%%time\\nscore = []\\nrnd = RandomizedSearchCV(pipe,.../grid_search_'+tar+'_.csv', sep=';', index=False)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"%%time\\nscore = []\\nrnd = RandomizedSearchCV(pipe,.../grid_search_'+tar+'_.csv', sep=';', index=False)\", store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-13-26803c1f7666>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n   2830                 code = compiler(mod, cell_name, \"single\")\n-> 2831                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f46eaf61810, file \"<ipython-input-13-26803c1f7666>\", line 1>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2832                     return True\n   2833 \n   2834             # Flush softspace\n   2835             if softspace(sys.stdout, 0):\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f46eaf61810, file \"<ipython-input-13-26803c1f7666>\", line 1>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f46eaf61810, file \"<ipython-input-13-26803c1f7666>\", line 1>\n        self.user_global_ns = {'AMLHelpers': <class '__main__.AMLHelpers'>, 'Capturing': <class '__main__.Capturing'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.feature_extract...edict, RandomizedSearchCV\\n\\nfrom gc import collect', \"TARGET = ['identity_hate', 'insult', 'obscene','severe_toxic', 'threat', 'toxic']\", \"data =  pd.read_csv('data/train.csv', sep=',', i...na(0, inplace=True)\\nprint(data.shape)\\ndata.head()\", \"pipe = Pipeline([('tfidf', TfidfVectorizer()), ('lg', LogisticRegression())])\", \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", \"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', \"pipe = Pipeline([('tfidf', TfidfVectorizer(input = 'file')), ('lg', LogisticRegression())])\", \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")'], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Magics': <class 'IPython.core.magic.Magics'>, 'Out': {3:                                                 ...01b41b1c6bb37e    1.0  \n0001d958c54c6e35    1.0  }, 'PYTHON_2': False, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n        self.user_ns = {'AMLHelpers': <class '__main__.AMLHelpers'>, 'Capturing': <class '__main__.Capturing'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.feature_extract...edict, RandomizedSearchCV\\n\\nfrom gc import collect', \"TARGET = ['identity_hate', 'insult', 'obscene','severe_toxic', 'threat', 'toxic']\", \"data =  pd.read_csv('data/train.csv', sep=',', i...na(0, inplace=True)\\nprint(data.shape)\\ndata.head()\", \"pipe = Pipeline([('tfidf', TfidfVectorizer()), ('lg', LogisticRegression())])\", \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", \"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', \"pipe = Pipeline([('tfidf', TfidfVectorizer(input = 'file')), ('lg', LogisticRegression())])\", \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")'], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Magics': <class 'IPython.core.magic.Magics'>, 'Out': {3:                                                 ...01b41b1c6bb37e    1.0  \n0001d958c54c6e35    1.0  }, 'PYTHON_2': False, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\n/home/cerdgio/notebooks/Toxic_comp/<ipython-input-13-26803c1f7666> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 get_ipython().run_cell_magic('time', '', \"score = []\\nrnd = RandomizedSearchCV(pipe, param_distributions=space, n_iter=200, scoring='neg_log_loss', \\n                       cv = 5, verbose=3, random_state=234, n_jobs = -1)\\nfor i, tar in enumerate(TARGET):\\n    print(tar)\\n    score.append(rnd.fit(data.loc[data.train==1, 'comment_text'], data.loc[data.train==1, tar].values))\\n    pd.DataFrame(score[i].cv_results_).to_csv('metrics/grid_search_'+tar+'_.csv', sep=';', index=False)\")\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name='time', line='', cell=\"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\")\n   2115             # This will need to be updated if the internal calling logic gets\n   2116             # refactored, or else we'll be expanding the wrong variables.\n   2117             stack_depth = 2\n   2118             magic_arg_s = self.var_expand(line, stack_depth)\n   2119             with self.builtin_trap:\n-> 2120                 result = fn(magic_arg_s, cell)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        magic_arg_s = ''\n        cell = \"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\"\n   2121             return result\n   2122 \n   2123     def find_line_magic(self, magic_name):\n   2124         \"\"\"Find and return a line magic by name.\n\n...........................................................................\n/home/cerdgio/notebooks/Toxic_comp/<decorator-gen-60> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell=\"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\", local_ns=None)\n      1 \n----> 2 \n      3 \n      4 \n      5 \n      6 \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/magic.py in <lambda>(f=<function ExecutionMagics.time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, '', \"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\", None), **k={})\n    188     validate_type(magic_kind)\n    189 \n    190     # This is a closure to capture the magic_kind.  We could also use a class,\n    191     # but it's overkill for just that one bit of state.\n    192     def magic_deco(arg):\n--> 193         call = lambda f, *a, **k: f(*a, **k)\n        f = <function ExecutionMagics.time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, '', \"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\", None)\n        k = {}\n    194 \n    195         if callable(arg):\n    196             # \"Naked\" decorator call (just @foo, no args)\n    197             func = arg\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/IPython/core/magics/execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell=\"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\", local_ns=None)\n   1172             st = clock2()\n   1173             out = eval(code, glob, local_ns)\n   1174             end = clock2()\n   1175         else:\n   1176             st = clock2()\n-> 1177             exec(code, glob, local_ns)\n        code = <code object <module> at 0x7f46eaf61a50, file \"<timed exec>\", line 1>\n        glob = {'AMLHelpers': <class '__main__.AMLHelpers'>, 'Capturing': <class '__main__.Capturing'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.feature_extract...edict, RandomizedSearchCV\\n\\nfrom gc import collect', \"TARGET = ['identity_hate', 'insult', 'obscene','severe_toxic', 'threat', 'toxic']\", \"data =  pd.read_csv('data/train.csv', sep=',', i...na(0, inplace=True)\\nprint(data.shape)\\ndata.head()\", \"pipe = Pipeline([('tfidf', TfidfVectorizer()), ('lg', LogisticRegression())])\", \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", \"score = []\\nrnd = RandomizedSearchCV(pipe, param_.../grid_search_'+tar+'_.csv', sep=';', index=False)\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")', \"pipe = Pipeline([('tfidf', TfidfVectorizer(input = 'file')), ('lg', LogisticRegression())])\", \"space = {\\n 'lg__C': [.0001, .001, .01, .1, 1.0, ...False,True]\\n #'tfidf__vocabulary': None\\n        }\", 'get_ipython().run_cell_magic(\\'time\\', \\'\\', \"score ...rid_search_\\'+tar+\\'_.csv\\', sep=\\';\\', index=False)\")'], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Magics': <class 'IPython.core.magic.Magics'>, 'Out': {3:                                                 ...01b41b1c6bb37e    1.0  \n0001d958c54c6e35    1.0  }, 'PYTHON_2': False, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n        local_ns = None\n   1178             end = clock2()\n   1179             out = None\n   1180         wall_end = wtime()\n   1181         # Compute actual times and report\n\n...........................................................................\n/home/cerdgio/notebooks/Toxic_comp/<timed exec> in <module>()\n      1 \n      2 \n      3 \n      4 \n      5 \n----> 6 \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=5, error_score='raise',\n  ...in_score=True, scoring='neg_log_loss', verbose=3), X=id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object, y=array([ 0.,  0.,  0., ...,  0.,  0.,  0.]), groups=None)\n   1185             train/test set.\n   1186         \"\"\"\n   1187         sampled_params = ParameterSampler(self.param_distributions,\n   1188                                           self.n_iter,\n   1189                                           random_state=self.random_state)\n-> 1190         return self._fit(X, y, groups, sampled_params)\n        self._fit = <bound method BaseSearchCV._fit of RandomizedSea...n_score=True, scoring='neg_log_loss', verbose=3)>\n        X = id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object\n        y = array([ 0.,  0.,  0., ...,  0.,  0.,  0.])\n        groups = None\n        sampled_params = <sklearn.model_selection._search.ParameterSampler object>\n   1191 \n   1192 \n   1193 \n   1194 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_search.py in _fit(self=RandomizedSearchCV(cv=5, error_score='raise',\n  ...in_score=True, scoring='neg_log_loss', verbose=3), X=id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object, y=array([ 0.,  0.,  0., ...,  0.,  0.,  0.]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterSampler object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterSampler object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nAttributeError                                     Mon Jan 22 05:17:42 2018\nPID: 84365                     Python 3.5.2: /anaconda/envs/py35/bin/python\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object, memmap([ 0.,  0.,  0., ...,  0.,  0.,  0.]), make_scorer(log_loss, greater_is_better=False, needs_proba=True), array([ 31658,  31916,  31917, ..., 159568, 159569, 159570]), array([    0,     1,     2, ..., 31913, 31914, 31915]), 3, {'lg__C': 100, 'lg__class_weight': {0: 1, 1: 4}, 'lg__fit_intercept': False, 'lg__max_iter': 1000, 'lg__penalty': 'l1', 'lg__random_state': 234, 'lg__tol': 0.01, 'lg__warm_start': False, 'tfidf__decode_error': 'ignore', 'tfidf__lowercase': False, ...}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object, memmap([ 0.,  0.,  0., ...,  0.,  0.,  0.]), make_scorer(log_loss, greater_is_better=False, needs_proba=True), array([ 31658,  31916,  31917, ..., 159568, 159569, 159570]), array([    0,     1,     2, ..., 31913, 31914, 31915]), 3, {'lg__C': 100, 'lg__class_weight': {0: 1, 1: 4}, 'lg__fit_intercept': False, 'lg__max_iter': 1000, 'lg__penalty': 'l1', 'lg__random_state': 234, 'lg__tol': 0.01, 'lg__warm_start': False, 'tfidf__decode_error': 'ignore', 'tfidf__lowercase': False, ...})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), X=id\n0000997932d777bf    Explanation\\nWhy the edit...u understand...\nName: comment_text, dtype: object, y=memmap([ 0.,  0.,  0., ...,  0.,  0.,  0.]), scorer=make_scorer(log_loss, greater_is_better=False, needs_proba=True), train=array([ 31658,  31916,  31917, ..., 159568, 159569, 159570]), test=array([    0,     1,     2, ..., 31913, 31914, 31915]), verbose=3, parameters={'lg__C': 100, 'lg__class_weight': {0: 1, 1: 4}, 'lg__fit_intercept': False, 'lg__max_iter': 1000, 'lg__penalty': 'l1', 'lg__random_state': 234, 'lg__tol': 0.01, 'lg__warm_start': False, 'tfidf__decode_error': 'ignore', 'tfidf__lowercase': False, ...}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...near', tol=0.01, verbose=0, warm_start=False))])>\n        X_train = id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object\n        y_train = memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), X=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, y=memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.]), **fit_params={})\n    263         Returns\n    264         -------\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n--> 268         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(steps=[(...near', tol=0.01, verbose=0, warm_start=False))])>\n        X = id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object\n        y = memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.])\n    269         if self._final_estimator is not None:\n    270             self._final_estimator.fit(Xt, y, **fit_params)\n    271         return self\n    272 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(steps=[('tfidf', TfidfVectorizer(analyz...inear', tol=0.01, verbose=0, warm_start=False))]), X=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, y=memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.]), **fit_params={})\n    229         Xt = X\n    230         for name, transform in self.steps[:-1]:\n    231             if transform is None:\n    232                 pass\n    233             elif hasattr(transform, \"fit_transform\"):\n--> 234                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt = id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object\n        transform.fit_transform = <bound method TfidfVectorizer.fit_transform of T... tokenizer=None, use_idf=False, vocabulary=None)>\n        y = memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.])\n        fit_params_steps = {'lg': {}, 'tfidf': {}}\n        name = 'tfidf'\n    235             else:\n    236                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    237                               .transform(Xt)\n    238         if self._final_estimator is None:\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=TfidfVectorizer(analyzer='word', binary=False, d...  tokenizer=None, use_idf=False, vocabulary=None), raw_documents=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, y=memmap([ 1.,  0.,  0., ...,  0.,  0.,  0.]))\n   1347         Returns\n   1348         -------\n   1349         X : sparse matrix, [n_samples, n_features]\n   1350             Tf-idf-weighted document-term matrix.\n   1351         \"\"\"\n-> 1352         X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n        X = undefined\n        self.fit_transform = <bound method TfidfVectorizer.fit_transform of T... tokenizer=None, use_idf=False, vocabulary=None)>\n        raw_documents = id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object\n   1353         self._tfidf.fit(X)\n   1354         # X is already a transformed view of raw_documents so\n   1355         # we set copy to False\n   1356         return self._tfidf.transform(X, copy=False)\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=TfidfVectorizer(analyzer='word', binary=False, d...  tokenizer=None, use_idf=False, vocabulary=None), raw_documents=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, y=None)\n    834         max_df = self.max_df\n    835         min_df = self.min_df\n    836         max_features = self.max_features\n    837 \n    838         vocabulary, X = self._count_vocab(raw_documents,\n--> 839                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    840 \n    841         if self.binary:\n    842             X.data.fill(1)\n    843 \n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in _count_vocab(self=TfidfVectorizer(analyzer='word', binary=False, d...  tokenizer=None, use_idf=False, vocabulary=None), raw_documents=id\n5414e44950efb072    Wait, you are female and ...u understand...\nName: comment_text, dtype: object, fixed_vocab=False)\n    757         indptr = _make_int_array()\n    758         values = _make_int_array()\n    759         indptr.append(0)\n    760         for doc in raw_documents:\n    761             feature_counter = {}\n--> 762             for feature in analyze(doc):\n        feature = undefined\n        analyze = <function VectorizerMixin.build_analyzer.<locals>.<lambda>>\n        doc = \"Wait, you are female and black..! That's disconcerting...\"\n    763                 try:\n    764                     feature_idx = vocabulary[feature]\n    765                     if feature_idx not in feature_counter:\n    766                         feature_counter[feature_idx] = 1\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in <lambda>(doc=\"Wait, you are female and black..! That's disconcerting...\")\n    236         elif self.analyzer == 'word':\n    237             stop_words = self.get_stop_words()\n    238             tokenize = self.build_tokenizer()\n    239 \n    240             return lambda doc: self._word_ngrams(\n--> 241                 tokenize(preprocess(self.decode(doc))), stop_words)\n        doc = \"Wait, you are female and black..! That's disconcerting...\"\n    242 \n    243         else:\n    244             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n    245                              self.analyzer)\n\n...........................................................................\n/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in decode(self=TfidfVectorizer(analyzer='word', binary=False, d...  tokenizer=None, use_idf=False, vocabulary=None), doc=\"Wait, you are female and black..! That's disconcerting...\")\n    110         if self.input == 'filename':\n    111             with open(doc, 'rb') as fh:\n    112                 doc = fh.read()\n    113 \n    114         elif self.input == 'file':\n--> 115             doc = doc.read()\n        doc = \"Wait, you are female and black..! That's disconcerting...\"\n        doc.read = undefined\n    116 \n    117         if isinstance(doc, bytes):\n    118             doc = doc.decode(self.encoding, self.decode_error)\n    119 \n\nAttributeError: 'str' object has no attribute 'read'\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = []\n",
    "rnd = RandomizedSearchCV(pipe, param_distributions=space, n_iter=200, scoring='neg_log_loss', \n",
    "                       cv = 5, verbose=3, random_state=234, n_jobs = -1)\n",
    "for i, tar in enumerate(TARGET):\n",
    "    print(tar)\n",
    "    score.append(rnd.fit(data.loc[data.train==1, 'comment_text'], data.loc[data.train==1, tar].values))\n",
    "    pd.DataFrame(score[i].cv_results_).to_csv('metrics/grid_search_'+tar+'_.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
